{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from classification import StockPredictor\n",
    "from DataLoader import DataLoader\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = 'AAPL'\n",
    "dataLoader = DataLoader() # if yahoo does not work use \"dataLoader.get_data_locally('AAPL')\"\n",
    "stock_data = dataLoader.pipeline(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>close</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>volume</th>\n",
       "      <th>max_5</th>\n",
       "      <th>min_5</th>\n",
       "      <th>max_10</th>\n",
       "      <th>min_10</th>\n",
       "      <th>max_20</th>\n",
       "      <th>...</th>\n",
       "      <th>stochastic_fast</th>\n",
       "      <th>stochastic_slow</th>\n",
       "      <th>%r</th>\n",
       "      <th>atr</th>\n",
       "      <th>cmo</th>\n",
       "      <th>cci</th>\n",
       "      <th>mom</th>\n",
       "      <th>bias</th>\n",
       "      <th>wnr</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>34272000</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.063528</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>...</td>\n",
       "      <td>69.987738</td>\n",
       "      <td>73.320430</td>\n",
       "      <td>42.871654</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>33.333058</td>\n",
       "      <td>38.811032</td>\n",
       "      <td>0.003005</td>\n",
       "      <td>0.666648</td>\n",
       "      <td>-0.333335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>37408000</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.063528</td>\n",
       "      <td>0.066962</td>\n",
       "      <td>...</td>\n",
       "      <td>69.987738</td>\n",
       "      <td>66.655047</td>\n",
       "      <td>50.014161</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>22.221858</td>\n",
       "      <td>38.747777</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.398933</td>\n",
       "      <td>-0.388891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>76092800</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.063528</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>...</td>\n",
       "      <td>59.989664</td>\n",
       "      <td>66.655047</td>\n",
       "      <td>66.675529</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>-6.666482</td>\n",
       "      <td>31.136203</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>-0.199563</td>\n",
       "      <td>-0.533332</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.062240</td>\n",
       "      <td>0.063099</td>\n",
       "      <td>0.062240</td>\n",
       "      <td>25244800</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.06224</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.06224</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>...</td>\n",
       "      <td>9.998248</td>\n",
       "      <td>46.658550</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>-22.221708</td>\n",
       "      <td>-88.316523</td>\n",
       "      <td>-0.001717</td>\n",
       "      <td>-3.268670</td>\n",
       "      <td>-0.611109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>0.064386</td>\n",
       "      <td>0.063957</td>\n",
       "      <td>31315200</td>\n",
       "      <td>0.064816</td>\n",
       "      <td>0.06224</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.06224</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>...</td>\n",
       "      <td>44.435023</td>\n",
       "      <td>38.140978</td>\n",
       "      <td>55.564977</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.833457</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.600405</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10937</th>\n",
       "      <td>206.089996</td>\n",
       "      <td>205.350006</td>\n",
       "      <td>206.990005</td>\n",
       "      <td>202.160004</td>\n",
       "      <td>101010600</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>205.350006</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>193.160004</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>62.787913</td>\n",
       "      <td>84.968448</td>\n",
       "      <td>37.212087</td>\n",
       "      <td>6.983572</td>\n",
       "      <td>26.197218</td>\n",
       "      <td>28.654023</td>\n",
       "      <td>8.370010</td>\n",
       "      <td>-0.685311</td>\n",
       "      <td>-0.369014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10938</th>\n",
       "      <td>203.100006</td>\n",
       "      <td>198.889999</td>\n",
       "      <td>204.100006</td>\n",
       "      <td>198.210007</td>\n",
       "      <td>69018500</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>198.889999</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>198.889999</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>36.686876</td>\n",
       "      <td>65.041315</td>\n",
       "      <td>84.292637</td>\n",
       "      <td>6.437143</td>\n",
       "      <td>16.565463</td>\n",
       "      <td>3.639740</td>\n",
       "      <td>5.729996</td>\n",
       "      <td>-4.075433</td>\n",
       "      <td>-0.417173</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10939</th>\n",
       "      <td>198.210007</td>\n",
       "      <td>198.509995</td>\n",
       "      <td>200.649994</td>\n",
       "      <td>197.020004</td>\n",
       "      <td>51216500</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>198.509995</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>198.509995</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>35.151503</td>\n",
       "      <td>44.875431</td>\n",
       "      <td>91.505184</td>\n",
       "      <td>6.431428</td>\n",
       "      <td>-4.332548</td>\n",
       "      <td>-11.938346</td>\n",
       "      <td>-1.230011</td>\n",
       "      <td>-4.201879</td>\n",
       "      <td>-0.521663</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10940</th>\n",
       "      <td>199.169998</td>\n",
       "      <td>196.250000</td>\n",
       "      <td>199.440002</td>\n",
       "      <td>193.250000</td>\n",
       "      <td>68536700</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>196.25</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>196.25</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>26.020212</td>\n",
       "      <td>32.619530</td>\n",
       "      <td>85.922101</td>\n",
       "      <td>6.175714</td>\n",
       "      <td>-32.376903</td>\n",
       "      <td>-40.056531</td>\n",
       "      <td>-8.350006</td>\n",
       "      <td>-4.909343</td>\n",
       "      <td>-0.661885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10941</th>\n",
       "      <td>197.720001</td>\n",
       "      <td>197.490005</td>\n",
       "      <td>200.050003</td>\n",
       "      <td>194.679993</td>\n",
       "      <td>50478900</td>\n",
       "      <td>205.350006</td>\n",
       "      <td>196.25</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>196.25</td>\n",
       "      <td>213.320007</td>\n",
       "      <td>...</td>\n",
       "      <td>31.030335</td>\n",
       "      <td>30.734017</td>\n",
       "      <td>80.103210</td>\n",
       "      <td>6.233572</td>\n",
       "      <td>-46.775485</td>\n",
       "      <td>-37.808412</td>\n",
       "      <td>-10.879990</td>\n",
       "      <td>-3.801376</td>\n",
       "      <td>-0.733877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10942 rows Ã— 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             open       close        high         low     volume       max_5  \\\n",
       "0        0.064816    0.064816    0.065245    0.064816   34272000    0.065674   \n",
       "1        0.064816    0.064816    0.065245    0.064816   37408000    0.065674   \n",
       "2        0.064816    0.064386    0.065245    0.064386   76092800    0.065674   \n",
       "3        0.063099    0.062240    0.063099    0.062240   25244800    0.064816   \n",
       "4        0.063957    0.063957    0.064386    0.063957   31315200    0.064816   \n",
       "...           ...         ...         ...         ...        ...         ...   \n",
       "10937  206.089996  205.350006  206.990005  202.160004  101010600  213.320007   \n",
       "10938  203.100006  198.889999  204.100006  198.210007   69018500  213.320007   \n",
       "10939  198.210007  198.509995  200.649994  197.020004   51216500  213.320007   \n",
       "10940  199.169998  196.250000  199.440002  193.250000   68536700  213.320007   \n",
       "10941  197.720001  197.490005  200.050003  194.679993   50478900  205.350006   \n",
       "\n",
       "            min_5      max_10      min_10      max_20  ... stochastic_fast  \\\n",
       "0        0.063528    0.065674    0.063099    0.066962  ...       69.987738   \n",
       "1        0.064386    0.065674    0.063528    0.066962  ...       69.987738   \n",
       "2        0.064386    0.065674    0.063528    0.065674  ...       59.989664   \n",
       "3         0.06224    0.065674     0.06224    0.065674  ...        9.998248   \n",
       "4         0.06224    0.065674     0.06224    0.065674  ...       44.435023   \n",
       "...           ...         ...         ...         ...  ...             ...   \n",
       "10937  205.350006  213.320007  193.160004  213.320007  ...       62.787913   \n",
       "10938  198.889999  213.320007  198.889999  213.320007  ...       36.686876   \n",
       "10939  198.509995  213.320007  198.509995  213.320007  ...       35.151503   \n",
       "10940      196.25  213.320007      196.25  213.320007  ...       26.020212   \n",
       "10941      196.25  213.320007      196.25  213.320007  ...       31.030335   \n",
       "\n",
       "      stochastic_slow          %r       atr        cmo        cci        mom  \\\n",
       "0           73.320430   42.871654  0.001196  33.333058  38.811032   0.003005   \n",
       "1           66.655047   50.014161  0.001196  22.221858  38.747777   0.001717   \n",
       "2           66.655047   66.675529  0.001196  -6.666482  31.136203  -0.000429   \n",
       "3           46.658550  100.000000  0.001134 -22.221708 -88.316523  -0.001717   \n",
       "4           38.140978   55.564977  0.001257   0.000000  -7.833457   0.000000   \n",
       "...               ...         ...       ...        ...        ...        ...   \n",
       "10937       84.968448   37.212087  6.983572  26.197218  28.654023   8.370010   \n",
       "10938       65.041315   84.292637  6.437143  16.565463   3.639740   5.729996   \n",
       "10939       44.875431   91.505184  6.431428  -4.332548 -11.938346  -1.230011   \n",
       "10940       32.619530   85.922101  6.175714 -32.376903 -40.056531  -8.350006   \n",
       "10941       30.734017   80.103210  6.233572 -46.775485 -37.808412 -10.879990   \n",
       "\n",
       "           bias       wnr target  \n",
       "0      0.666648 -0.333335      0  \n",
       "1      0.398933 -0.388891      0  \n",
       "2     -0.199563 -0.533332      0  \n",
       "3     -3.268670 -0.611109      1  \n",
       "4     -0.600405 -0.500000      1  \n",
       "...         ...       ...    ...  \n",
       "10937 -0.685311 -0.369014      0  \n",
       "10938 -4.075433 -0.417173      0  \n",
       "10939 -4.201879 -0.521663      0  \n",
       "10940 -4.909343 -0.661885      1  \n",
       "10941 -3.801376 -0.733877      1  \n",
       "\n",
       "[10942 rows x 52 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      50.34%   69.83%   58.51%      4916  \n",
      "       1      52.51%   32.63%   40.25%      5026  \n",
      "                                                  \n",
      "   Macro      51.43%   51.23%   49.38%            \n",
      "   Micro      51.03%   51.03%   51.03%            \n",
      "Weighted      51.44%   51.03%   49.28%            \n",
      "\n",
      "                 51.03% accuracy                  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.51,\n",
       "    class  precision  recall     f1\n",
       " 0      0      0.503   0.698  0.585\n",
       " 1      1      0.525   0.326  0.403)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_predictor = StockPredictor(stock_data=stock_data, \n",
    "                                 model_names_list=[\"lgbm\", \"mlp\", \"xgboost\", \"randomforest\"],\n",
    "                                 ensemble_strategy=\"majority_vote\",\n",
    "                                 drift_name='adwin',\n",
    "                                 feature_selector_name='selectkbest_sklearn',\n",
    "                                 learning_threshold = 1000,\n",
    "                                 ensemble_params={'n_models': 10}\n",
    "                                 )\n",
    "stock_predictor.prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_predictor.drifts_detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      51.20%   55.21%   53.13%      4916  \n",
      "       1      52.55%   48.53%   50.46%      5026  \n",
      "                                                  \n",
      "   Macro      51.88%   51.87%   51.79%            \n",
      "   Micro      51.83%   51.83%   51.83%            \n",
      "Weighted      51.88%   51.83%   51.78%            \n",
      "\n",
      "                 51.83% accuracy                  \n",
      "hoeffdingtreeclassifier BaggingClassifier 0.518\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      48.77%   30.78%   37.74%      4916  \n",
      "       1      50.25%   68.38%   57.93%      5026  \n",
      "                                                  \n",
      "   Macro      49.51%   49.58%   47.84%            \n",
      "   Micro      49.79%   49.79%   49.79%            \n",
      "Weighted      49.52%   49.79%   47.95%            \n",
      "\n",
      "                 49.79% accuracy                  \n",
      "hoeffdingtreeclassifier AdaBoostClassifier 0.498\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      50.98%   48.07%   49.48%      4916  \n",
      "       1      51.89%   54.80%   53.30%      5026  \n",
      "                                                  \n",
      "   Macro      51.44%   51.43%   51.39%            \n",
      "   Micro      51.47%   51.47%   51.47%            \n",
      "Weighted      51.44%   51.47%   51.41%            \n",
      "\n",
      "                 51.47% accuracy                  \n",
      "hoeffdingtreeclassifier ADWINBaggingClassifier 0.515\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      50.08%   51.97%   51.01%      4916  \n",
      "       1      51.22%   49.32%   50.25%      5026  \n",
      "                                                  \n",
      "   Macro      50.65%   50.65%   50.63%            \n",
      "   Micro      50.63%   50.63%   50.63%            \n",
      "Weighted      50.66%   50.63%   50.63%            \n",
      "\n",
      "                 50.63% accuracy                  \n",
      "hoeffdingtreeclassifier SRPClassifier 0.506\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.29%   37.67%   42.71%      4916  \n",
      "       1      50.46%   62.10%   55.68%      5026  \n",
      "                                                  \n",
      "   Macro      49.88%   49.88%   49.19%            \n",
      "   Micro      50.02%   50.02%   50.02%            \n",
      "Weighted      49.88%   50.02%   49.26%            \n",
      "\n",
      "                 50.02% accuracy                  \n",
      "hoeffdingtreeclassifier LeveragingBaggingClassifier 0.5\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      52.50%   42.11%   46.73%      4916  \n",
      "       1      52.56%   62.73%   57.20%      5026  \n",
      "                                                  \n",
      "   Macro      52.53%   52.42%   51.96%            \n",
      "   Micro      52.53%   52.53%   52.53%            \n",
      "Weighted      52.53%   52.53%   52.02%            \n",
      "\n",
      "                 52.53% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier BaggingClassifier 0.525\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.57%   47.95%   48.74%      4916  \n",
      "       1      50.67%   52.29%   51.46%      5026  \n",
      "                                                  \n",
      "   Macro      50.12%   50.12%   50.10%            \n",
      "   Micro      50.14%   50.14%   50.14%            \n",
      "Weighted      50.12%   50.14%   50.12%            \n",
      "\n",
      "                 50.14% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier AdaBoostClassifier 0.501\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      52.12%   45.97%   48.85%      4916  \n",
      "       1      52.62%   58.69%   55.49%      5026  \n",
      "                                                  \n",
      "   Macro      52.37%   52.33%   52.17%            \n",
      "   Micro      52.40%   52.40%   52.40%            \n",
      "Weighted      52.37%   52.40%   52.21%            \n",
      "\n",
      "                 52.40% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier ADWINBaggingClassifier 0.524\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      48.95%   52.07%   50.46%      4916  \n",
      "       1      50.00%   46.88%   48.39%      5026  \n",
      "                                                  \n",
      "   Macro      49.47%   49.48%   49.43%            \n",
      "   Micro      49.45%   49.45%   49.45%            \n",
      "Weighted      49.48%   49.45%   49.41%            \n",
      "\n",
      "                 49.45% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier SRPClassifier 0.494\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.22%   54.13%   51.56%      4916  \n",
      "       1      50.29%   45.38%   47.71%      5026  \n",
      "                                                  \n",
      "   Macro      49.75%   49.76%   49.63%            \n",
      "   Micro      49.71%   49.71%   49.71%            \n",
      "Weighted      49.76%   49.71%   49.61%            \n",
      "\n",
      "                 49.71% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier LeveragingBaggingClassifier 0.497\n"
     ]
    }
   ],
   "source": [
    "result_rows = []\n",
    "for base_model in [\"hoeffdingtreeclassifier\", \"extremelyfastdecisiontreeclassifier\"]:\n",
    "    for ensemble in ['BaggingClassifier', 'AdaBoostClassifier', 'ADWINBaggingClassifier', 'SRPClassifier', 'LeveragingBaggingClassifier']:\n",
    "        stock_predictor = StockPredictor(stock_data=stock_data, \n",
    "                                 model_names_list=[base_model],\n",
    "                                 ensemble_strategy=ensemble,\n",
    "                                 drift_name='adwin',\n",
    "                                 feature_selector_name='selectkbest',\n",
    "                                 learning_threshold = 1000,\n",
    "                                 ensemble_params={'n_models': 5}\n",
    "                                 )\n",
    "        accuracy, metrics_result = stock_predictor.prediction()\n",
    "        print(base_model, ensemble, accuracy)\n",
    "        result_rows.append([base_model, ensemble, 'adwin', 'selectkbest', 1000, 1, round(accuracy, 3), stock_predictor.drifts_detected, {}, ticker])\n",
    "        \n",
    "result_df = pd.DataFrame(result_rows, columns=['ensemble_name', 'model_name', 'drift_name', 'feature_selector_name', 'learning_threshold', 'iteration', 'accuracy', 'drifts_detected', 'model_args', 'ticker'])\n",
    "result_df.to_csv('ensemble_results_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      51.52%   41.15%   45.75%      4916  \n",
      "       1      51.90%   62.12%   56.55%      5026  \n",
      "                                                  \n",
      "   Macro      51.71%   51.63%   51.15%            \n",
      "   Micro      51.75%   51.75%   51.75%            \n",
      "Weighted      51.71%   51.75%   51.21%            \n",
      "\n",
      "                 51.75% accuracy                  \n",
      "hoeffdingtreeclassifier BaggingClassifier 0.518\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.66%   45.14%   47.29%      4916  \n",
      "       1      50.73%   55.25%   52.90%      5026  \n",
      "                                                  \n",
      "   Macro      50.20%   50.20%   50.09%            \n",
      "   Micro      50.25%   50.25%   50.25%            \n",
      "Weighted      50.20%   50.25%   50.13%            \n",
      "\n",
      "                 50.25% accuracy                  \n",
      "hoeffdingtreeclassifier AdaBoostClassifier 0.503\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      50.49%   51.28%   50.88%      4916  \n",
      "       1      51.61%   50.82%   51.21%      5026  \n",
      "                                                  \n",
      "   Macro      51.05%   51.05%   51.05%            \n",
      "   Micro      51.05%   51.05%   51.05%            \n",
      "Weighted      51.05%   51.05%   51.05%            \n",
      "\n",
      "                 51.05% accuracy                  \n",
      "hoeffdingtreeclassifier ADWINBaggingClassifier 0.51\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      50.31%   39.24%   44.09%      4916  \n",
      "       1      51.10%   62.10%   56.06%      5026  \n",
      "                                                  \n",
      "   Macro      50.70%   50.67%   50.08%            \n",
      "   Micro      50.79%   50.79%   50.79%            \n",
      "Weighted      50.71%   50.79%   50.14%            \n",
      "\n",
      "                 50.79% accuracy                  \n",
      "hoeffdingtreeclassifier SRPClassifier 0.508\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.63%   48.98%   49.30%      4916  \n",
      "       1      50.73%   51.37%   51.05%      5026  \n",
      "                                                  \n",
      "   Macro      50.18%   50.18%   50.18%            \n",
      "   Micro      50.19%   50.19%   50.19%            \n",
      "Weighted      50.18%   50.19%   50.19%            \n",
      "\n",
      "                 50.19% accuracy                  \n",
      "hoeffdingtreeclassifier LeveragingBaggingClassifier 0.502\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      51.65%   39.46%   44.74%      4916  \n",
      "       1      51.89%   63.87%   57.26%      5026  \n",
      "                                                  \n",
      "   Macro      51.77%   51.67%   51.00%            \n",
      "   Micro      51.80%   51.80%   51.80%            \n",
      "Weighted      51.77%   51.80%   51.07%            \n",
      "\n",
      "                 51.80% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier BaggingClassifier 0.518\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.66%   49.23%   49.44%      4916  \n",
      "       1      50.76%   51.19%   50.98%      5026  \n",
      "                                                  \n",
      "   Macro      50.21%   50.21%   50.21%            \n",
      "   Micro      50.22%   50.22%   50.22%            \n",
      "Weighted      50.22%   50.22%   50.22%            \n",
      "\n",
      "                 50.22% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier AdaBoostClassifier 0.502\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      52.87%   41.09%   46.24%      4916  \n",
      "       1      52.69%   64.17%   57.86%      5026  \n",
      "                                                  \n",
      "   Macro      52.78%   52.63%   52.05%            \n",
      "   Micro      52.76%   52.76%   52.76%            \n",
      "Weighted      52.78%   52.76%   52.12%            \n",
      "\n",
      "                 52.76% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier ADWINBaggingClassifier 0.528\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.25%   50.83%   50.03%      4916  \n",
      "       1      50.35%   48.77%   49.55%      5026  \n",
      "                                                  \n",
      "   Macro      49.80%   49.80%   49.79%            \n",
      "   Micro      49.79%   49.79%   49.79%            \n",
      "Weighted      49.81%   49.79%   49.78%            \n",
      "\n",
      "                 49.79% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier SRPClassifier 0.498\n",
      "           Precision   Recall   F1       Support  \n",
      "                                                  \n",
      "       0      49.32%   51.28%   50.28%      4916  \n",
      "       1      50.41%   48.45%   49.41%      5026  \n",
      "                                                  \n",
      "   Macro      49.86%   49.86%   49.85%            \n",
      "   Micro      49.85%   49.85%   49.85%            \n",
      "Weighted      49.87%   49.85%   49.84%            \n",
      "\n",
      "                 49.85% accuracy                  \n",
      "extremelyfastdecisiontreeclassifier LeveragingBaggingClassifier 0.498\n"
     ]
    }
   ],
   "source": [
    "result_rows = []\n",
    "for base_model in [\"hoeffdingtreeclassifier\", \"extremelyfastdecisiontreeclassifier\"]:\n",
    "    for ensemble in ['BaggingClassifier', 'AdaBoostClassifier', 'ADWINBaggingClassifier', 'SRPClassifier', 'LeveragingBaggingClassifier']:\n",
    "        stock_predictor = StockPredictor(stock_data=stock_data, \n",
    "                                 model_names_list=[base_model],\n",
    "                                 ensemble_strategy=ensemble,\n",
    "                                 drift_name='adwin',\n",
    "                                 feature_selector_name='selectkbest',\n",
    "                                 learning_threshold = 1000,\n",
    "                                 ensemble_params={'n_models': 10}\n",
    "                                 )\n",
    "        accuracy, metrics_result = stock_predictor.prediction()\n",
    "        print(base_model, ensemble, accuracy)\n",
    "        result_rows.append([base_model, ensemble, 'adwin', 'selectkbest', 1000, 1, round(accuracy, 3), stock_predictor.drifts_detected, {}, ticker])\n",
    "        \n",
    "result_df = pd.DataFrame(result_rows, columns=['ensemble_name', 'model_name', 'drift_name', 'feature_selector_name', 'learning_threshold', 'iteration', 'accuracy', 'drifts_detected', 'model_args', 'ticker'])\n",
    "result_df.to_csv('ensemble_results_df_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
